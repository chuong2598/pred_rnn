{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = np.load(\"mnist_train_seq.npy\")\n",
    "test_set =  np.load(\"mnist_test_seq.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpatialTemoralLSTMCell(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, image_shape, in_channel, hidden_channels, kernel_size, stride=1):\n",
    "        super(SpatialTemoralLSTMCell, self).__init__()\n",
    "        \"\"\"\n",
    "        hidden_channels: Number of hidden features map \n",
    "        \"\"\"\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.padding = kernel_size//2\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.g_bias, self.i_bias, self.f_bias, self.o_bias, self.g_prime_bias, self.i_prime_bias, self.f_prime_bias = torch.nn.Parameter(torch.rand(7))\n",
    "        \n",
    "        self.conv_x = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=self.hidden_channels*7, kernel_size=kernel_size, padding=self.padding, stride=self.stride),\n",
    "            torch.nn.LayerNorm([hidden_channels*7, image_shape[0], image_shape[1]])\n",
    "        )\n",
    "        \n",
    "        self.conv_h_prev = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=self.hidden_channels, out_channels=self.hidden_channels*4, kernel_size=kernel_size, padding=self.padding, stride=self.stride),\n",
    "            torch.nn.LayerNorm([hidden_channels*4, image_shape[0], image_shape[1]])\n",
    "        )\n",
    "        \n",
    "        self.conv_m_prev = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=self.hidden_channels, out_channels=self.hidden_channels*3, kernel_size=kernel_size, padding=self.padding, stride=self.stride),\n",
    "            torch.nn.LayerNorm([hidden_channels*3, image_shape[0], image_shape[1]])\n",
    "        )\n",
    "        \n",
    "        self.conv_c = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=self.hidden_channels, out_channels=self.hidden_channels, kernel_size=kernel_size, padding=self.padding, stride=self.stride),\n",
    "            torch.nn.LayerNorm([hidden_channels, image_shape[0], image_shape[1]])\n",
    "        )\n",
    "        \n",
    "        self.conv_m = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=self.hidden_channels, out_channels=self.hidden_channels, kernel_size=kernel_size, padding=self.padding, stride=self.stride),\n",
    "            torch.nn.LayerNorm([hidden_channels, image_shape[0], image_shape[1]])\n",
    "        )\n",
    "        \n",
    "        self.conv_c_m = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=self.hidden_channels*2, out_channels=self.hidden_channels, kernel_size=1, padding=0, stride=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev, m_prev):\n",
    "        conv_x = self.conv_x(x)\n",
    "        g_x, i_x, f_x, o_x, g_x_prime, i_x_prime, f_x_prime = torch.split(tensor=conv_x, split_size_or_sections=self.hidden_channels, dim=1)\n",
    "        conv_h_prev = self.conv_h_prev(h_prev)\n",
    "        g_h, i_h, f_h, o_h = torch.split(tensor=conv_h_prev, split_size_or_sections=self.hidden_channels, dim=1)\n",
    "        g = torch.tanh(g_x + g_h + self.g_bias)\n",
    "        i = torch.sigmoid(i_x + i_h + self.i_bias)\n",
    "        f = torch.sigmoid(f_x + f_h + self.f_bias)\n",
    "        c = f * c_prev + i * g\n",
    "        \n",
    "        conv_m_prev = self.conv_m_prev(m_prev)\n",
    "        g_m_prime, i_m_prime, f_m_prime = torch.split(tensor=conv_m_prev, split_size_or_sections=self.hidden_channels, dim=1)\n",
    "        g_prime = torch.tanh(g_x_prime + g_m_prime + self.g_prime_bias)\n",
    "        i_prime = torch.sigmoid(i_x_prime + i_m_prime + self.i_prime_bias)\n",
    "        f_prime = torch.sigmoid(f_x_prime + f_m_prime + self.f_prime_bias)\n",
    "        m = f_prime * m_prev + i_prime * g_prime\n",
    "        \n",
    "        o_c = self.conv_c(c)\n",
    "        o_m = self.conv_m(m)\n",
    "        o = torch.sigmoid(o_x + o_h + o_c + o_m + self.o_bias)\n",
    "        \n",
    "        c_m_cat = torch.cat((c,m), dim=1)\n",
    "        h = o * torch.tanh(self.conv_c_m(c_m_cat))\n",
    "        \n",
    "        return h, c, m\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PredRNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_layers, image_shape, in_channel, hidden_layer_dim, kernel_size, stride=1, device=\"cuda\"):\n",
    "        super(PredRNN, self).__init__()\n",
    "        \n",
    "        self.nb_layers = nb_layers\n",
    "        self.hidden_layer_dim = hidden_layer_dim\n",
    "        self.cell_list = []\n",
    "        # Fixed hidden layer dim for every layer ==> Fix later by changing param hidden_layer_dim from int to list of int\n",
    "        for i in range(nb_layers):\n",
    "            if i == 0:\n",
    "                new_cell = SpatialTemoralLSTMCell(image_shape=image_shape, in_channel=in_channel, \n",
    "                                                  hidden_channels=hidden_layer_dim, kernel_size=kernel_size, stride=stride)\n",
    "            else:\n",
    "                new_cell = SpatialTemoralLSTMCell(image_shape=image_shape, in_channel=hidden_layer_dim, \n",
    "                                                  hidden_channels=hidden_layer_dim, kernel_size=kernel_size, stride=stride)\n",
    "            self.cell_list.append(new_cell)\n",
    "            \n",
    "        self.cell_list = torch.nn.ModuleList(self.cell_list)\n",
    "        self.output_conv = torch.nn.Conv2d(in_channels=hidden_layer_dim, out_channels=in_channel, kernel_size=1, stride=1)\n",
    "            \n",
    "    \n",
    "    def forward(self, batch_of_sequences):\n",
    "        batch, length, nb_channels, height, width = batch_of_sequences.shape\n",
    "        \n",
    "        # h_list = torch.zeros(batch, length, self.hidden_layer_dim, height, width, device=device)\n",
    "        # c_list = torch.zeros(batch, length, self.hidden_layer_dim, height, width, device=device)\n",
    "        # memory = torch.zeros(batch, self.hidden_layer_dim, height, width, device=device)\n",
    "        \n",
    "        # # Recurrent flow (For each timestep, perform vertical flow first)\n",
    "        # for t in range(length):\n",
    "        #     h_list[:, 0], c_list[:, 0], memory = self.cell_list[0](batch_of_sequences[:, t], h_list[:, 0], c_list[:, 0], memory)\n",
    "            \n",
    "        #     for layer in range(1, self.nb_layers):\n",
    "        #         h_list[:, layer], c_list[:, layer], memory = self.cell_list[layer](h_list[:, layer-1], h_list[:, layer], c_list[:, layer], memory)\n",
    "        \n",
    "        # pred = self.output_conv(h_list[:, -1])\n",
    "        h_list = []\n",
    "        c_list = []\n",
    "        for i in range(self.nb_layers):\n",
    "            h_list.append(torch.zeros(batch, self.hidden_layer_dim, height, width, device=device))\n",
    "            c_list.append(torch.zeros(batch, self.hidden_layer_dim, height, width, device=device))\n",
    "\n",
    "        memory = torch.zeros(batch, self.hidden_layer_dim, height, width, device=device)\n",
    "\n",
    "        # Recurrent flow (For each timestep, perform vertical flow first)\n",
    "        for t in range(length):\n",
    "            h_list[0], c_list[0], memory = self.cell_list[0](batch_of_sequences[:, t], h_list[0], c_list[0], memory)\n",
    "            for layer in range(1, self.nb_layers):\n",
    "                h_list[layer], c_list[layer], memory = self.cell_list[layer](h_list[layer-1], h_list[layer], c_list[layer], memory)\n",
    "        \n",
    "        pred = self.output_conv(h_list[-1])\n",
    "\n",
    "        return pred\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test cell\n",
    "# batch_size = 1\n",
    "# test_tensor = torch.randn((batch_size, 3, 10, 10))\n",
    "# test_h_prev = torch.randn((batch_size, 5, 10, 10))\n",
    "# test_c_prev = torch.randn((batch_size, 5, 10, 10))\n",
    "# test_m_prev = torch.randn((batch_size, 5, 10, 10))\n",
    "\n",
    "# test_cell = SpatialTemoralLSTMCell(image_shape=(10,10,3), in_channel=3, hidden_channels=5, kernel_size=5, stride=1)\n",
    "\n",
    "# h, c, m = test_cell(test_tensor, test_h_prev, test_c_prev, test_m_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test PredRNN\n",
    "# batch_size, length, channels, height, width = 16, 10, 3, 64, 64\n",
    "# test_tensor = torch.randn(batch_size, length, channels, height, width)\n",
    "\n",
    "# pred_rnn = PredRNN(nb_layers=3, image_shape=(height, width, channels), in_channel=channels, hidden_layer_dim=8, kernel_size=5, stride=1)\n",
    "# pred = pred_rnn(test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
